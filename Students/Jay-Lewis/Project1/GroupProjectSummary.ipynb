{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Classification of Natural vs. Computer Generated Images*\n",
    "\n",
    "## Authors\n",
    "* Yixiao Feng\n",
    "* Jyothsna Kurra\n",
    "* Justin Lewis\n",
    "* Tim Woodbury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview:\n",
    "\n",
    "* Two sets of training data given: Natural (\"scenes\") and computer generated (\"synthetic\")\n",
    "* Model-based classification\n",
    "* Generalized detection approach:\n",
    "    * Identify appropriate features\n",
    "    * Train models for the features\n",
    "    * Validate selected models against the provided data sets\n",
    "    \n",
    "Four strategies are considered for discriminating scenes and synthetic images.\n",
    "These are as follows: (1) edge detection; (2) grayscale intensity; (3) RGB peak density; (4) image sharpness.\n",
    "The strategies are each discussed in one of the following sections, in which both the motivation for a particular strategy and results are shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I) Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection is considered to distinguish synthetic and natural images.\n",
    "Natural images, which have greater sources of distortion and imperfect lighting, are expected to have a greater number of pixels detectable as edges.\n",
    "This section will present the basic approach used including the training of models for hypothesis testing.\n",
    "Subsequently the likelihood ratio test for image discrimination is presented and the correct classification rate is discussed.\n",
    "\n",
    "#### Approach\n",
    "Gradient-based edge detection is used.\n",
    "Pixels for which the gradient exceeds a fixed threshold are classified as edges.\n",
    "The threshold is determined using a training set of 23 each synthetic and natural images.\n",
    "The following figure shows normalized histograms of the pixel gradients across all images in the data sets.\n",
    "Based on the histogram, a threshold value of 4 was chosen.\n",
    "All pixels whose gradients exceed the threshold are classified as edges.\n",
    "\n",
    "<img style=\"float: left;\" src=\"img1.png\">\n",
    "\n",
    "The threshold is applied to the same training set.\n",
    "For uniformity, each image is resized to $(540 \\times 960)$ before it is processed, ensuring that differences in edge counts are not due to differences in size.\n",
    "The number of edge pixels, as determined by the threshold on the gradient, is then totalled.\n",
    "Applying this metric to the synthetic and natural images separately, a histogram for the number of edge pixels in the training images is obtained.\n",
    "These histograms are shown in the following figure.\n",
    "\n",
    "<img style=\"float: left;\" src=\"img2.png\">\n",
    "\n",
    "The histograms are coarse because of the small size of the training sets.\n",
    "However, they provide a means for determining a plausible probability density function (PDF) for the synthetic and natural image sets.\n",
    "The histograms have very wide tails, so Cauchy distributions are fit to the data.\n",
    "The Cauchy distributions for natural and synthetic images have the following parameters:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{scenes}: x_0 = 131700, \\gamma = 52984.7 \\\\\n",
    "\\mathrm{synthetic}: x_0 = 35760.8, \\gamma = 5377.61\n",
    "\\end{align}\n",
    "\n",
    "Here, $x_0$ indicates the mean and $\\gamma$ the scale parameter.\n",
    "Having determined approximate distributions for the number of edges in the synthetic and natural images, it is a straightforward matter to apply a likelihood ratio test for a new candidate image to classify it as synthetic or natural.\n",
    "\n",
    "#### Likelihood ratio test and performance\n",
    "\n",
    "The likelihood ratio test compares the lieklihood of the measured datum, $z$, for the two candidate hypothesis.\n",
    "A Bayesian framework is incorporated, so we arbitrarily can choose \"synthetic\" as the null hypothesis and \"natural\" as the test hypothesis.\n",
    "In the Bayesian framework, the likelihood ratio is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{Pr(H_0)}{Pr(H_1)} \\lessgtr \\frac{p_0(z)}{p_1(z)}\n",
    "\\end{equation}\n",
    "\n",
    "$Pr(H_i)$ indicates the probability of a hypothesis $H_i$ and $p_i(z)$ is the associated probability density function for the test statistic.\n",
    "For simplicity, synthetic and natural images are treated as equally likely, so the likelihood ratio is compared to one.\n",
    "The following figure shows the likelihood ratios for the synthetic and natural image sets.\n",
    "The likelihood threshold based on the priors is plotted for comparison.\n",
    "Clearly, the test is conservative with respect to synthetic images, and fails to detect all the natural scenes.\n",
    "No doubt better performance could be obtained using larger training sets and a more refined edge detection scheme.\n",
    "\n",
    "<img style=\"float: left;\" src=\"img3.png\">\n",
    "\n",
    "Using equal priors, there are zero false positives out of ninety-nine synthetic images and seven false negatives out of fifty-six natural scenes.\n",
    "This is a total error rate of just about 4.5% for the whole data set.\n",
    "It should be noted that the test set includes the images used in training the statistics for the Cauchy distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II) Grayscale Intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach: \n",
    "Synthetic and natural images are expected to have measureably different intensity distributions.\n",
    "Natural images, in general, are expected to have a smoother distribution of intensity values, while synthetic images have a sharper distributions.\n",
    "The strategy is to compute the sum of the difference between adjacent bins of the grayscale histogram, which should be a function of histogram smoothness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple illustration of natural image histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Image_codeline3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitted  Image Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image shows a histogram of the grayscale intensity metric for the natural images.\n",
    "A normal distribution fit to the data is shown, and is used to approximate the distribution for computing the likelihood ratio.\n",
    "\n",
    "<img src=\"Image_codeline9.png\">\n",
    "\n",
    "The following image shows a histogram of the grayscale intensity metric for the synthetic images.\n",
    "\n",
    "<img src=\"Image_codeline9(2).png\">\n",
    "\n",
    "The final image shows the distributions for the natural images (blue) and the synthetic images (green).\n",
    "The continuous PDFs are used in a likelihood ratio test for new images in the same fashion introduced in Section 1.\n",
    "\n",
    "<img src=\"Image_codeline9(3).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "\n",
    "The proposed likelihood ratio test based on grayscale histogram difference is evaluated on the available image sets.\n",
    "In this section, the null hypothesis is a natural image, so the false positive rate indicates the fraction of images incorrectly classified as synthetic.\n",
    "\n",
    "* False Positive Rate: 9.6%\n",
    "* False Negative Rate: 26.5%\n",
    "* Total Error Rate: 18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III) RGB Peak Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach\n",
    "\n",
    "The intensity-based metric of Section 2 performs reasonably well.\n",
    "However, it seems plausble that better performance could be achieved by leveraging the color information of the images.\n",
    "This is particularly reasonable, since the synthetic images are all of the same 3D models.\n",
    "The limitation with this approach is that it is not practical to develop a model that is predictive for all of the natural images.\n",
    "\n",
    "The feature of interest is essentially the same metric as in Section 2, but for all three color channels (R,G,B) simultaneously.\n",
    "Essentially it is desired to look at the sharpness of all three color histograms.\n",
    "The feature metric is the sum of the squared maximum difference within the subhistograms.\n",
    "Taking $\\Delta_i$ to be the difference between adjacent histogram bins for color channel $i$, the metric is written as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "z = \\max ( \\Delta_{red} )^2 + \\max ( \\Delta_{green} )^2 + \\max ( \\Delta_{blue} )^2\n",
    "\\end{equation}\n",
    "\n",
    "To motivate the use of this metric, consider the following examples of red color histograms from one natural image and one scene.\n",
    "\n",
    "#### Example of Scene RGB Histogram:\n",
    "\n",
    "<img src=\"sceneRhist.png\">\n",
    "\n",
    "#### Example of Synthetic RGB Histogram:\n",
    "\n",
    "<img src=\"synthRhist.png\">\n",
    "\n",
    "Clearly, for the particular case considered, the peak of the red channel histogram is much \"sharper\" for the synthetic image.\n",
    "The following sub-section presents representative training histograms and summarizes performance of a likelihood-ratio-based image detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Threshold Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method Explanation:\n",
    "\n",
    "* Distribution fit: after several different attempts to fit a distribution to the metric histograms, cauchy CDFs were chosen\n",
    "* Threshold: the decision region for both hypotheses was decided by using a threshold on the Log Likelihood Ratio. The threshold on the feature metric value was found to be 3.8e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Metric Histograms:\n",
    "\n",
    "<img src=\"metrichistogram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitted Distribution Plot:\n",
    "\n",
    "<img src=\"fitteddists.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance\n",
    "\n",
    "* False Positive Rate:    0.415\n",
    "* False Negative Rate:    0.163\n",
    "* Overall Error Rate:     0.289"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV) Image Sharpness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach\n",
    "\n",
    "We shall use the following principle to design our statistical model in order to perform the binary detection of images: \"A sharper good quality image will have higher number of high frequency components compared to a blurred image.\"\n",
    "As the synthetic (computer generated) images has sharper edges when compared to the natural (photographic/scenic) images, hence, the synthetic image shall contain greater number of high frequency components when compared to the natural images.\n",
    "The image blur metric is derived from the paper by De and Masilamani [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Explanation\n",
    "\n",
    "Ref. [1] defines an image sharpness metric that is adapted in the present work to differentiate the sharper synthetic images from natural images.\n",
    "The sharpness metric based on the 2D fast Fourier transform (FFT) of the image.\n",
    "The metric is the fraction of pixels that exceed 1/1000th of the peak absolute FFT value.\n",
    "Characteristic values of the metric for synthetic and natural images are computed from training sets, as follows.\n",
    "20 images from each of the sets are taken as training data.\n",
    "The following figures show histograms for the image sharpness metric in the synthetic and natural image training sets:\n",
    "\n",
    "<img src=\"index.png\">\n",
    "\n",
    "<img src=\"index2.png\">\n",
    "\n",
    "\n",
    "The histograms are treated as probability mass functions and used in a likelihood ratio test as in previous sections.\n",
    "For these distributions, the likelihood ratio is monotonic and can be converted to a threshold on the sharpness metric.\n",
    "That threshold is taken as $0.71$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assume our test hypothesis ($H_1$) to be the detection of computer generated images, the probabilities of false alarm and miss detection are given as follows:\n",
    "\n",
    "* The Rate of False Alarms is: 0.057\n",
    "* The Rate of Missed Detections is: 0.028\n",
    "* The Accuracy of the Detector is: 91.428 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summarized:\n",
    "\n",
    "### I) Edge Detection\n",
    "#### Total Error Rate: 4.5%\n",
    "\n",
    "### II) Grayscale Intensity\n",
    "#### Total Error Rate: 18.0%\n",
    "\n",
    "### III) RGB Peak Density\n",
    "####  Total Error Rate: 27.0%\n",
    "\n",
    "### IV) Image Sharpness\n",
    "####  Total Error Rate: 8.5%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Intensity and RGB methods work well for computer generated images which are dominated by a few colors; however, in this way it is more limiting than other methods.\n",
    "* Analyzing this problem within the Fourier Domain space seems more robust than analyzing color or intensity sharpness. There were several images within the scene set which would have been very difficult to distinguish based on predominating color. \n",
    "* Additionally, analysis of spatial variation also seems to be more robust than the intensity/RGB methods. Many natural photos are prone to more spatial noise. This noise is amplified by derivative-esque transformations and could prove as distinguishable for a wider range of photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References\n",
    "[1] D. Kanjar, V. Masilamani. \"Image sharpness measure for blurred images in frequency domain.\" Procedia Eng, 64 (2013), pp. 149â€“158."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
