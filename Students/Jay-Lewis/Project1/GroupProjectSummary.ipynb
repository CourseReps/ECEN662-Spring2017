{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Classification of Natural vs. Computer Generated Images*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview:\n",
    "\n",
    "* Two sets of training data given: Natural and Comp. Gen\n",
    "* Statistics based detection approach to classification\n",
    "* Generalized detection approach:\n",
    "    * feature detection\n",
    "    * data fitting\n",
    "    * threshold testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies Implemented:\n",
    "\n",
    "### I) Edge Detection\n",
    "### II) Grayscale Intensity\n",
    "### III) RGB Peak Density\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I) Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection is considered to distinguish synthetic and natural images.\n",
    "Natural images, which have greater sources of distortion and imperfect lighting, are expected to have a greater number of pixels detectable as edges.\n",
    "This section will present the basic approach used including the training of models for hypothesis testing.\n",
    "Subsequently the likelihood ratio test for image discrimination is presented and the correct classification rate is discussed.\n",
    "\n",
    "#### Approach\n",
    "Gradient-based edge detection is used.\n",
    "Pixels for which the gradient exceeds a fixed threshold are classified as edges.\n",
    "The threshold is determined using a training set of 23 each synthetic and natural images.\n",
    "The following figure shows normalized histograms of the pixel gradients across all images in the data sets.\n",
    "Based on the histogram, a threshold value of 4 was chosen.\n",
    "All pixels whose gradients exceed the threshold are classified as edges.\n",
    "\n",
    "<img style=\"float: left;\" src=\"img1.png\">\n",
    "\n",
    "The threshold is applied to the same training set.\n",
    "For uniformity, each image is resized to $(540 \\times 960)$ before it is processed, ensuring that differences in edge counts are not due to differences in size.\n",
    "The number of edge pixels, as determined by the threshold on the gradient, is then totalled.\n",
    "Applying this metric to the synthetic and natural images separately, a histogram for the number of edge pixels in the training images is obtained.\n",
    "These histograms are shown in the following figure.\n",
    "\n",
    "<img style=\"float: left;\" src=\"img2.png\">\n",
    "\n",
    "The histograms are coarse because of the small size of the training sets.\n",
    "However, they provide a means for determining a plausible probability density function (PDF) for the synthetic and natural image sets.\n",
    "The histograms have very wide tails, so Cauchy distributions are fit to the data.\n",
    "The Cauchy distributions for natural and synthetic images have the following parameters:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{scenes}: x_0 = 131700, \\gamma = 52984.7 \\\\\n",
    "\\mathrm{synthetic}: x_0 = 35760.8, \\gamma = 5377.61\n",
    "\\end{align}\n",
    "\n",
    "Here, $x_0$ indicates the mean and $\\gamma$ the scale parameter.\n",
    "Having determined approximate distributions for the number of edges in the synthetic and natural images, it is a straightforward matter to apply a likelihood ratio test for a new candidate image to classify it as synthetic or natural.\n",
    "\n",
    "#### Likelihood ratio test and performance\n",
    "\n",
    "The likelihood ratio test compares the lieklihood of the measured datum, $z$, for the two candidate hypothesis.\n",
    "A Bayesian framework is incorporated, so we arbitrarily can choose \"synthetic\" as the null hypothesis and \"natural\" as the test hypothesis.\n",
    "In the Bayesian framework, the likelihood ratio is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{Pr(H_0)}{Pr(H_1)} \\lessgtr \\frac{p_0(z)}{p_1(z)}\n",
    "\\end{equation}\n",
    "\n",
    "$Pr(H_i)$ indicates the probability of a hypothesis $H_i$ and $p_i(z)$ is the associated probability density function for the test statistic.\n",
    "For simplicity, synthetic and natural images are treated as equally likely, so the likelihood ratio is compared to one.\n",
    "The following figure shows the likelihood ratios for the synthetic and natural image sets.\n",
    "The likelihood threshold based on the priors is plotted for comparison.\n",
    "Clearly, the test is conservative with respect to synthetic images, and fails to detect all the natural scenes.\n",
    "No doubt better performance could be obtained using larger training sets and a more refined edge detection scheme.\n",
    "\n",
    "<img style=\"float: left;\" src=\"img3.png\">\n",
    "\n",
    "Using equal priors, there are zero false positives out of ninety-nine synthetic images and seven false negatives out of fifty-six natural scenes.\n",
    "This is a total error rate of just about 4.5% for the whole data set.\n",
    "It should be noted that the test set includes the images used in training the statistics for the Cauchy distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II) Grayscale Intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach: \n",
    "Compute the sum of difference between (neighbor) points of grayscale histogram (describes histogram smoothness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple illustration of natural image histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images in the project/Image_codeline3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitted  Image Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images in the project/Image_codeline9.png\">\n",
    "<img src=\"Images in the project/Image_codeline9(2).png\">\n",
    "<img src=\"Images in the project/Image_codeline9(3).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "* False Positive Rate: 9.6%\n",
    "* False Negative Rate: 26.5%\n",
    "* Total Error Rate: 18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III) RGB Peak Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach\n",
    "\n",
    "* Feacture of interest: sharpness of peak values within RGB histograms\n",
    "* Feature metric: sum of squared maximum difference within subhistogram around max values\n",
    "\n",
    "\n",
    "* Code Snipet:\n",
    "~~~~\n",
    "    Rmaxdiff = np.diff(Rsubhist).max()\n",
    "    Gmaxdiff = np.diff(Gsubhist).max()\n",
    "    Bmaxdiff = np.diff(Bsubhist).max()\n",
    "\n",
    "    metric = pow(Rmaxdiff,2)+pow(Gmaxdiff,2)+pow(Bmaxdiff,2)\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Scene RGB Histogram:\n",
    "\n",
    "<img src=\"sceneRhist.png\">\n",
    "\n",
    "#### Example of Synthetic RGB Histogram:\n",
    "\n",
    "<img src=\"synthRhist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Threshold Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method Explanation:\n",
    "\n",
    "* Distribution fit: after several different attempts to fit a distribution to the metric histograms, cauchy CDFs were chosen\n",
    "* Threshold: the decision region for both hypotheses was decided by using a threshold on the Log Likelihood Ratio. The threshold on the feature metric value was found to be 3.8e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Metric Histograms:\n",
    "\n",
    "<img src=\"metrichistogram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitted Distribution Plot:\n",
    "\n",
    "<img src=\"fitteddists.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance\n",
    "\n",
    "* False Positive Rate:    *0.415*\n",
    "* False Negative Rate:    *0.163*\n",
    "\n",
    "* Overal Error Rate:      *0.289*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summarized:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I) Edge Detection\n",
    "#### Total Error Rate: 4.5%\n",
    "\n",
    "### II) Grayscale Intensity\n",
    "#### Total Error Rate: 10.0%\n",
    "\n",
    "### III) RGB Peak Density\n",
    "####  Total Error Rate: 30.0%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Intensity and RGB methods work well for computer generated images which are dominated by a few colors; however, in this way it is more limiting than other methods.\n",
    "* Analyzing this problem within the Fourier Domain space seems more robust than analyzing color or intensity sharpness. There were several images within the scene set which would have been very difficult to distinguish based on predominating color. \n",
    "* Additionally, analysis of spatial variation also seems to be more robust than the intensity/RGB methods. Many natural photos are prone to more spatial noise. This noise is amplified by derivative-esque transformations and could prove as distinguishable for a wider range of photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
