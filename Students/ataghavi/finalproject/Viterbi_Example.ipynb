{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm Example\n",
    "\n",
    "## Problem Introduction\n",
    "\n",
    "This example shows an implementation of the Viterbi algorithm to solve a simple and classic example of a Hidden Markov Model (HMM). In this example, our observable states represent a person's physical state. The three states are \"normal\", \"cold\", and \"dizzy\". Our Hidden Markov Process is a two-state process indicating whether or not the person is \"Healthy\" or has a \"Fever\".\n",
    "\n",
    "## Defining the models\n",
    "\n",
    "First, we write the Markov model in terms of the states, transition probabilities, and emission probabilities for the various observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs = ('normal', 'normal', 'normal', 'dizzy', 'dizzy', 'cold')\n",
    "states = ('Healthy', 'Fever')\n",
    "start_p = {'Healthy': 0.6, 'Fever': 0.4}\n",
    "trans_p = {\n",
    "   'Healthy' : {'Healthy': 0.7, 'Fever': 0.3},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.6}\n",
    "   }\n",
    "emit_p = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6}\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model diagram\n",
    "\n",
    "![title](HMM_example.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Algorithm Function\n",
    "\n",
    "The Viterbi algorithm is a dynamic programming algorithm that keeps a table of the likely Markov chains, ending in each state, at each time step. It begins by storing in the table, for time 0, the probability of starting with each starting state and emitting the starting observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = [{}]\n",
    "for st in states:\n",
    "    V[0][st] = {\"prob\": start_p[st] * emit_p[st][obs[0]], \"prev\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for each time step, we compute the most likely path ending in each state, and then the probability of this path emitting the observation for that time step. In this sense, it is very similar to the dynamic programming algorithms for shortest path (Dijkstra and Bellman-Ford)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in range(1, len(obs)):\n",
    "    V.append({})\n",
    "    for st in states:\n",
    "        max_tr_prob = max(V[t-1][prev_st][\"prob\"]*trans_p[prev_st][st] for prev_st in states)\n",
    "        for prev_st in states:\n",
    "            if V[t-1][prev_st][\"prob\"] * trans_p[prev_st][st] == max_tr_prob:\n",
    "                max_prob = max_tr_prob * emit_p[st][obs[t]]\n",
    "                V[t][st] = {\"prob\": max_prob, \"prev\": prev_st}\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we look through the resulting table to find the most likely final state of the Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = []\n",
    "max_prob = max(value[\"prob\"] for value in V[-1].values())\n",
    "previous = None\n",
    "for st, data in V[-1].items():\n",
    "    if data[\"prob\"] == max_prob:\n",
    "        opt.append(st)\n",
    "        previous = st\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use the table to find the previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in range(len(V) - 2, -1, -1):\n",
    "    opt.insert(0, V[t + 1][previous][\"prev\"])\n",
    "    previous = V[t + 1][previous][\"prev\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can print the Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The steps of states are ( Healthy-> Healthy-> Healthy-> Fever-> Fever-> Fever ) with highest probability of 0.000428652\n"
     ]
    }
   ],
   "source": [
    "print 'The steps of states are ( ' + '-> '.join(opt) + ' ) with highest probability of %s' % max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
